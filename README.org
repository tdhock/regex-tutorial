#+TITLE: Tutorial on named capture regular expressions in R and Python

#+SETUPFILE: ~/src/org-html-themes/setup/theme-readtheorg.setup

# disable underscore subscripts
#+OPTIONS: ^:nil

In this 60 minute tutorial I will explain how to use named capture
regular expressions to extract data from several different kinds
structured text data.

For additional reading see my R journal articles about [[https://github.com/tdhock/namedCapture-article][namedCapture]] and [[https://github.com/tdhock/nc-article][nc]].

** Motivation for using named capture regular expressions, 5 minutes

Why would you want to use named capture regular expressions? They are
useful when you want to extract groups of substrings from text data
which has some structure, but no consistent delimiter such as tabs or
commas between groups. They make it easy to convert such loosely
structured text data into regular CSV/TSV data.
- The regular expression =5 foo bar= matches any string that contains
  =5 foo bar= as a substring.
- The regular expression =foo|bar= matches any string that contains
  =foo= or =bar=. The vertical bar indicates *alternation* -- if any one
  of the options is present, then there is a match.
- Square brackets are used to indicate a *character class*. The
  regular expression =[0-9] foo bar= means match any digit, followed
  by a space, followed by =foo bar=.
- A *capturing* regular expression includes parentheses for extracting
  data when there is a match. For example if we apply the regular
  expression =([0-9]) (foo|bar)= to the string =prefix 8 foo suffix=,
  we put =8= in the first capture group and =foo= in the second.
- A *named capture* regular expression includes group names. For
  example if we apply the regular expression =(?<number>[0-9])
  (?<string>foo|bar)= to the string =prefix 8 foo suffix=, we put =8=
  in the capture group named =number=, and =foo= in the capture group
  named =string=.

Named capture regular expressions are better than simple capturing
regular expressions, since you can refer to the extracted data by
*name* rather than by an arbitrary index. That results in code that is
a bit more verbose, but much easier to understand. For example in
Python,

#+BEGIN_SRC python
import re
subject = 'chr10:213,054,000-213,055,000'
# Without named capture:
group_tuple = re.search("(chr.*?):(.*?)-([0-9,]*)", subject).groups()
print group_tuple[1]
# With named capture:
group_dict = re.search(r"""
(?P<chrom>chr.*?)
:
(?P<chromStart>.*?)
-
(?P<chromEnd>[0-9,]*)
""", subject, re.VERBOSE).groupdict()
print group_dict["chromStart"]
#+END_SRC

Both print statements show the same thing, but the intent of the
second is clearer for two reasons:
- The group names in the regular expression serve to document their
  purpose. Regular expressions have a bad reputation as a [[http://regex.info/blog/2006-09-15/247][write-only
  language]] but named capture can be used to make them more readable:
  "Hmmm... what was the second group =.*?= supposed to match?  Oh
  yeah, the chromStart!"
- We can extract the data by group name (chromStart) rather than an
  arbitrary index (1), clarifying the intent of the Python code.

** History, 5 minutes

| Who            | When | First                           |
|----------------+------+---------------------------------|
| Kleene         | 1956 | Regular expression on paper     |
| Thompson       | 1968 | Regular expression in a program |
| Thompson       | 1974 | grep                            |
| Wall           | 1994 | Perl5 =(?= extensions           |
| Hazel          | 1997 | PCRE                            |
| Kuchling et al | 1997 | Named capture in Python1.5      |
| R core         | 2002 | PCRE in R                       |
| Hazel          | 2003 | Named capture in PCRE           |
| Hocking        | 2011 | Named capture in R              |
| Hocking        | 2016 | extractall in Python pandas     |

Regular sets and regular expressions were introduced on paper by
Stephen Cole Kleene in 1956 (including the "Kleene star" =*= for zero
or more). Among the first uses of a regular expression in a program
was Ken Thompson (Bachelors 1965, Masters 1966, UC Berkeley) for his
version of the QED (1968) and ed (1969) text editors, developed at
Bell Labs for Unix. In ed, =g/re/p= means "Global Regular Expression
Print," which gave the name to the grep program, also written by
Thompson (1974). I'm not sure about the origin of capture groups, but
Friedl claimed that "The regular expressions supported by grep and
other early tools were quite limited...grep's capturing metacharacters
were =\(...\)=, with unescaped parentheses representing literal
text." Larry Wall wrote Perl version 1 in 1987 while working at Unisys
Corporation, and it had capturing regular expressions. Perl version 5
in 1994 introduced many extensions using the =(?= notation. Sources:
[[https://en.wikipedia.org/w/index.php?title%3DRegular_expression&oldid%3D682153405][wikipedia:Regular_expression]] and "A Casual Stroll Across the Regex
Landscape," in Ch.3 of Friedl's book Mastering Regular Expressions.

Philip Hazel started writing the Perl-Compatible Regular Expressions
(PCRE) library for the exim mail program in 1997. Python used PCRE
starting with version 1.5 in 1997. Source: [[file:python-1.5.2-Misc-HISTORY.txt][Python-1.5/Misc/HISTORY]].

#+BEGIN_SRC text
From 1.5a3 to 1.5a4...
- A completely new re.py module is provided (thanks to Andrew
Kuchling, Tim Peters and Jeffrey Ollie) which uses Philip Hazel's
"pcre" re compiler and engine.
#+END_SRC

Python 1.5 introduced named capture groups and the =(?P<name>subpattern)=
syntax. Source: [[file:python-1.5-Doc-libre.tex][Python-1.5/Doc/libre.tex]].

#+BEGIN_SRC tex
\item[\code{(?P<\var{name}>...)}] Similar to regular parentheses, but
the text matched by the group is accessible via the symbolic group
name \var{name}.
#+END_SRC

PCRE support for named capture was introduced in 2003. Source: [[http://pcre.org/original/changelog.txt][PCRE
changelog]] ([[file:pcre1-changelog.txt][my copy]]).

#+BEGIN_SRC text
Version 4.0 17-Feb-03...
36. Added support for named subpatterns. The Python syntax (?P<name>...) is
used to name a group. Names consist of alphanumerics and underscores, and must
be unique. Back references use the syntax (?P=name) and recursive calls use
(?P>name) which is a PCRE extension to the Python extension. Groups still have
numbers.
#+END_SRC

PCRE supports alternative syntax for named capture in 2006:
#+BEGIN_SRC text
Version 7.0 19-Dec-06
...
34. Added a number of extra features that are going to be in Perl 5.10. On the
    whole, these are just syntactic alternatives for features that PCRE had
    previously implemented using the Python syntax or my own invention. The
    other formats are all retained for compatibility.

    (a) Named groups can now be defined as (?<name>...) or (?'name'...) as well
        as (?P<name>...). The new forms, as well as being in Perl 5.10, are
        also .NET compatible.
#+END_SRC
R includes PCRE starting with version 1.6.0 in 2002. Source:
[[file:R.NEWS.1.txt][R-src/NEWS.1]].

#+BEGIN_SRC text
CHANGES IN R VERSION 1.6.0...
    o	grep(), (g)sub() and regexpr() have a new argument `perl'
	which if TRUE uses Perl-style regexps from PCRE (if installed).
#+END_SRC

I wrote the code in https://svn.r-project.org/R/trunk/src/main/grep.c
which implements named capture regular expression support for R. It
was merged into base R in 2011
https://bugs.r-project.org/bugzilla3/show_bug.cgi?id=14518, and has
been included with every copy of R since version 2.14.

I wrote the =str.extractall= method in [[http://pandas.pydata.org/][pandas]], first included with
release version 0.18.0 ([[https://github.com/pydata/pandas/pull/11386][my Pull Request]] was merged in Feb 2016).

** Current usage in R and Python, 10 minutes

When developing complex regular expressions, it is useful to have
interactive visual feedback about what parts of your subject string
matches. This functionality is provided by [[http://www.emacswiki.org/emacs/ReBuilder][M-x re-builder]] ([[https://www.masteringemacs.org/article/re-builder-interactive-regexp-builder][mastering
emacs]]) and web pages such as [[http://pythex.org/][pythex]].

For a subject =s= (R character vector or Python pandas Series) and a
regular expression pattern =p= (string),

| R namedCapture package      | Python pandas         | returns                     |
|-----------------------------+-----------------------+-----------------------------|
| =str_match_named(s, p)=     | =s.str.extract(p)=    | first match in each subject |
| =str_match_all_named(s, p)= | =s.str.extractall(p)= | all matches in each subject |

*** Named capture in R

Base R supports named capture regular expressions via C code that
interfaces the Perl-Compatible Regular Expressions (PCRE) library.
The base functions =regexpr(p, s)= and =gregexpr(p, s)= use PCRE when
given the perl=TRUE argument. The first argument =p= is a single
regular expression *pattern* (character vector of length 1), and the
second argument =s= is the character vector of *subjects* (strings to
parse). However their output is a bunch of integers and group names,
which is not very user-friendly.

Instead I recommend using the [[https://github.com/tdhock/namedCapture][namedCapture]] package, which provides the
=str_match_named(s, p)= and =str_match_all_named(s, p)=
functions. They are a user-friendly interface to the base =regexpr=
and =gregexpr= functions. They return character matrices with column
names as defined in the named groups of the regular expression. To
install the namedCapture package, run the following commands in R:

#+BEGIN_SRC R
if(!require(devtools))install.packages("devtools")
devtools::install_github("tdhock/namedCapture")
#+END_SRC

Notes on related functions/packages: 
- =regexec= and =regmatches= in base R implement extracting capture
  groups but the =regexec= man page indicates that perl=TRUE (and thus
  named capture) is not implemented.
- =stringr::str_match= and =stringi::stri_match= implement extracting
  capture groups, but [[https://github.com/hadley/stringr/pull/16][the stringi package does not support named capture yet as such a
 feature set is still considered as experimental in ICU]]. 
- https://github.com/tdhock/revector provides fast C code for a
  *vector* of named capture regular expressions (base R only provides
  functions for a single regular expression).
  
*** Named capture in Python

The [[https://docs.python.org/2/library/re.html][re]] module of the Python Standard Library implements named capture
regular expression support via the =m.groupdict()= method for a [[https://docs.python.org/2/library/re.html#match-objects][match
object]] =m=.

For data analysis I recommend using the [[http://pandas.pydata.org/][pandas]] library, which supports
named capture regular expressions via the =s.str.extract(p)= and
=s.str.extractall(p)= methods for a *subject* Series =s= and a regular
expression *pattern* =p=. Both methods are an interface to the =re=
module, and return a =DataFrame= with one row per match and one column
per capture group. To install pandas execute one of the following
shell commands:

#+BEGIN_SRC shell-script
pip install pandas
easy_install pandas
#+END_SRC

Note that in Python a =P= is required after the initial question mark
of each group: =(?P<name>pattern)=. In contrast, in
R/PCRE/namedCapture the =P= is allowed but not required.

** Some exercises

| Exercises         | data                                | code/solution              | functions                                  |
|-------------------+-------------------------------------+----------------------------+--------------------------------------------|
|                   |                                     | [[file:chr.pos.R]]             | str_match_named, str_match_all_named, gsub |
|                   |                                     | [[file:differences_from_R.py]] | re.search, re.compile                      |
|                   |                                     | [[file:chr_pos.py]]            | str.extract, str.findall, re.subn          |
| [[file:qsub-out/README.org][qsub exercises]]    | [[file:qsub-out][qsub data]]                           | [[file:qsub-out.R]]            | str_match_named                            |
| [[file:trackDb.org][trackDb exercises]] | [[file:trackDb.txt]], [[file:trackDb2.txt]] | [[file:trackDb.R]]             | str_match_all_named                        |
| [[file:R-Forge.org][R-Forge exercises]] | [[file:R-Forge/]]                       |                            | str_match_named, str_match_all_named       |
| [[file:SweeD/README.org][SweeD exercises]]   | [[file:SweeD/]]                         |                            | nc::capture_all_str                        |
| [[file:NEWS/README.org][NEWS conversion]]   | [[file:NEWS/old/]]                      |                            | nc::capture_all_str                        |
| [[file:cran-check-logs/README.org][CRAN check logs]]   | [[file:cran-check-logs/]]               | TODO blog link             | nc::capture_all_str                        |

** Questions from the audience, 10 minutes

How do you ever extracted data from text files? Show us how you
extracted some data from a particular text file, and we will try to
suggest improvements.

** Polynomial time named capture

Russ Cox's "[[https://swtch.com/~rsc/regexp/regexp1.html][Regular Expression Matching Can Be Simple And Fast]]"
explains that due to backreference support, several common regular
expression engines can have an exponential runtime (including PCRE
which is used by R and Python). One way to achieve a speedup is to
drop backreference support and use the [[https://github.com/google/re2][re2]] C++ library, [[https://github.com/google/re2/wiki/Syntax][which supports
named capture]]. [[https://github.com/qinwf][Qin Wenfeng]] implemented the excellent [[https://github.com/qinwf/re2r][re2r]] package as
his [[https://github.com/rstats-gsoc/gsoc2016/wiki/re2-regular-expressions][Google Summer of Code 2016 project]]. If you need a provably fast
(polynomial time) regular expression engine in R, I recommend using
re2r! One example of when re2r is useful: [[https://docs.microsoft.com/en-us/dotnet/standard/base-types/best-practices][validating email using a
specific problematic pattern]]. Also speed benchmarks below and in the
[[http://qinwenfeng.com/re2r_doc/re2r-benchmark.html][re2r vignette]].

| R function            | library | named capture | complexity  |
|-----------------------+---------+---------------+-------------|
| regexpr(perl=FALSE)   | TRE     | no            | polynomial  |
| stringi::stri_match() | ICU     | no            | exponential |
| regexpr(perl=TRUE)    | PCRE    | yes           | exponential |
| str_match_re2()       | re2     | yes           | polynomial  |

#+BEGIN_SRC R
  if(!require(re2r))devtools::install_github("qinwf/re2r", build_vignettes=FALSE, dep=FALSE)
  if(!require(stringi))install.packages("stringi")
  
  max.N <- 25
  times.list <- list()
  for(N in 1:max.N){
    cat(sprintf("subject/pattern size %4d / %4d\n", N, max.N))
    subject <- paste(rep("a", N), collapse="")
    pattern <- paste(rep(c("a?", "a"), each=N), collapse="")
    N.times <- microbenchmark::microbenchmark(
      ICU=stringi::stri_match(subject, regex=pattern),
      PCRE=regexpr(pattern, subject, perl=TRUE),
      TRE=regexpr(pattern, subject, perl=FALSE),
      RE2=re2r::re2_match(pattern, subject),
      times=10)
    times.list[[N]] <- data.frame(N, N.times)
  }
  times <- do.call(rbind, times.list)
  save(times, file="times.RData")
  
  library(ggplot2)
  library(directlabels)
  linear.legend <- ggplot()+
    ggtitle("Timing regular expressions in R, linear scale")+
    scale_y_continuous("seconds")+
    scale_x_continuous("subject/pattern size",
                       limits=c(1, 27),
                       breaks=c(1, 5, 10, 15, 20, 25))+
    geom_point(aes(N, time/1e9, color=expr),
               shape=1,
               data=times)
  (linear.dl <- direct.label(linear.legend, "last.polygons"))
  png("figure-complexity-linear.png")
  print(linear.dl)
  dev.off()
  
  log.legend <- ggplot()+
    ggtitle("Timing regular expressions in R, log scale")+
    scale_y_log10("seconds")+
    scale_x_log10("subject/pattern size",
                  limits=c(1, 30),
                  breaks=c(1, 5, 10, 15, 20, 25))+
    geom_point(aes(N, time/1e9, color=expr),
               shape=1,
               data=times)
  (log.dl <- direct.label(log.legend, "last.polygons"))
  png("figure-complexity-log.png")
  print(log.dl)
  dev.off()
#+END_SRC

[[file:figure-complexity-linear.png]] 

[[file:figure-complexity-log.png]]  

** References

http://www.regular-expressions.info has some basic reference on how to
write regular expressions in several languages. However it discusses
neither named capture in R, nor pandas in Python.

The definitive reference on current regular expression implementations
is the book "Mastering Regular Expressions," by Jeffrey
E.F. Freidl. It contains a discussion of Python and named capture, but
discusses neither pandas nor R.

